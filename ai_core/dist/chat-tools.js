// Tool definitions for chat API
import { tool } from 'ai';
import { z } from 'zod';
import { generateInteriorImage, buildInteriorDesignPrompt } from './imagen/generate-interior';
import { generateInteriorImageI2I, buildI2IEditingPrompt } from './imagen/generate-interior-i2i';
// ‚úÖ VISION + T2I: Static imports (no I2I fallback needed)
import { analyzeRoomStructure } from './vision/analyze-room';
import crypto from 'node:crypto';
// Factory function to create tools with injected sessionId
export function createChatTools(sessionId) {
    // Define schemas first - ‚úÖ CHAIN OF THOUGHT: Forza l'AI a riflettere sulla struttura prima del prompt
    const GenerateRenderParameters = z.object({
        // 1Ô∏è‚É£ STEP 1: Analizza la struttura (Chain of Thought)
        structuralElements: z.string()
            .min(20)
            .describe('MANDATORY: List ALL structural elements visible in the user photo or mentioned in the request (in ENGLISH). ' +
            'Examples: "arched window on left wall", "exposed wooden ceiling beams", "parquet flooring", "high ceilings 3.5m". ' +
            'If no photo was uploaded, describe the structural requests from the conversation (e.g., "large kitchen island", "walk-in shower").'),
        // 2Ô∏è‚É£ STEP 2: Type & Style (gi√† esistenti)
        roomType: z.string().min(3).describe('MANDATORY: Type of room in ENGLISH (e.g. "kitchen", "bathroom").'),
        style: z.string().min(3).describe('MANDATORY: Design style in ENGLISH (e.g. "industrial", "modern").'),
        // 3Ô∏è‚É£ STEP 3: Prompt finale (DEVE usare structuralElements)
        prompt: z.string()
            .min(30)
            .describe('MANDATORY: The final detailed prompt for the image generator IN ENGLISH. ' +
            'MUST start by describing the structuralElements listed above. ' +
            'Example: "A modern living room featuring a large arched window on the left wall, exposed wooden beams on the ceiling, and oak parquet flooring. The space includes..."'),
        // üÜï HYBRID TOOL PARAMETERS (Optional - backward compatible)
        // 4Ô∏è‚É£ Mode selection (creation vs modification)
        mode: z.enum(['creation', 'modification'])
            .optional()
            .default('creation')
            .describe('Choose "modification" if user uploaded a photo and wants to transform that specific room. ' +
            'Choose "creation" if user is describing an imaginary room from scratch. ' +
            'DEFAULT: "creation" if not specified.'),
        // 5Ô∏è‚É£ Source image URL (required for modification mode)
        sourceImageUrl: z.string()
            .url()
            .optional()
            .describe('REQUIRED if mode="modification". The public HTTPS URL of the uploaded user photo (from Firebase Storage). ' +
            'Search conversation history for URLs like "https://storage.googleapis.com/...". ' +
            'If user uploaded a photo but you cannot find the URL, ask them to re-upload. ' +
            'Leave empty for mode="creation".'),
        // 6Ô∏è‚É£ Modification Type (for model selection)
        modificationType: z.enum(['renovation', 'detail'])
            .optional()
            .default('renovation')
            .describe('Choose "renovation" for whole-room transformation (default). ' +
            'Choose "detail" for small edits (e.g., "change sofa color", "add plant"). ' +
            'This selects the appropriate AI model.'),
    });
    const SubmitLeadParameters = z.object({
        name: z.string().max(100).describe('Customer name'),
        email: z.string().email().max(200).describe('Customer email'),
        phone: z.string().max(20).optional().describe('Customer phone number'),
        projectDetails: z.string().max(2000).describe('Detailed project description'),
        roomType: z.string().max(100).optional().describe('Type of room'),
        style: z.string().max(100).optional().describe('Preferred style'),
    });
    return {
        generate_render: tool({
            description: `Generate a photorealistic 3D rendering of an interior design.
            
            IMPORTANT CONFIRMATION RULE:
            DO NOT call without confirmation! First summarize collected details and ask: "Vuoi che proceda con la generazione?"
            
            CRITICAL - AFTER THIS TOOL RETURNS:
            You MUST include the returned imageUrl in your next response using markdown format.
            Example: "Ecco il rendering!\\n\\n![](RETURNED_IMAGE_URL)\\n\\nTi piace?"
            
            The imageUrl will be in the tool result under result.imageUrl - you MUST display it with ![](url) syntax.`,
            parameters: GenerateRenderParameters,
            execute: async (args) => {
                // Extract all parameters including new hybrid parameters
                const { prompt, roomType, style, structuralElements, mode, sourceImageUrl, modificationType } = args || {};
                try {
                    // Use sessionId from closure (injected via factory)
                    console.log('üèóÔ∏è [Chain of Thought] Structural elements detected:', structuralElements);
                    console.log('üõ†Ô∏è [Hybrid Tool] Mode selected:', mode || 'creation (default)');
                    console.log('üîß [Hybrid Tool] Modification Type:', modificationType || 'renovation (default)');
                    console.log('üé® [generate_render] RECEIVED ARGS:', { prompt, roomType, style, mode, hasSourceImage: !!sourceImageUrl });
                    const safeRoomType = (roomType || 'room').substring(0, 100);
                    const safeStyle = (style || 'modern').substring(0, 100);
                    // FAILSAFE: If prompt is empty/short, regenerate it
                    let safePrompt = prompt || `Interior design of a ${safeRoomType} in ${safeStyle} style`;
                    if (safePrompt.length < 10) {
                        console.warn('‚ö†Ô∏è [Failsafe] Short prompt detected, regenerating...');
                        safePrompt = `${safeStyle} style ${safeRoomType} with ${structuralElements || 'modern design'}`;
                    }
                    console.log('üî• [generate_render] Safe Prompt used:', safePrompt);
                    // üîÄ ROUTING LOGIC: Choose T2I (creation) or I2I (modification)
                    let imageBuffer;
                    let enhancedPrompt;
                    const actualMode = mode || 'creation'; // Default to creation for backward compatibility
                    // üîç DEBUG LOGGING
                    console.log('üîç [DEBUG] actualMode:', actualMode);
                    console.log('üîç [DEBUG] sourceImageUrl:', sourceImageUrl);
                    console.log('üîç [DEBUG] mode param:', mode);
                    console.log('üîç [DEBUG] Condition met?', actualMode === 'modification' && sourceImageUrl);
                    if (actualMode === 'modification' && sourceImageUrl) {
                        try {
                            // ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
                            // üì∏ PHOTO-BASED RENOVATION: Vision Analysis ‚Üí T2I
                            // ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
                            console.log('[Vision] üì∏ PHOTO-BASED MODE: Analyzing with Gemini Vision ‚Üí T2I');
                            console.log('[Vision] Reference photo:', sourceImageUrl);
                            // Step 1: Analyze room structure with Gemini Vision
                            console.log('[Vision] Step 1: Analyzing room structure...');
                            const roomAnalysis = await analyzeRoomStructure(sourceImageUrl);
                            console.log('[Vision] ‚úÖ Analysis complete');
                            console.log('[Vision] Detected:', roomAnalysis.room_type, `(~${roomAnalysis.approximate_size_sqm}sqm)`);
                            console.log('[Vision] Features:', roomAnalysis.architectural_features.join(', '));
                            // Step 2: Build super-detailed prompt from Vision analysis
                            // ‚úÖ REFACTOR: Use I2I Prompt Builder directly (preserving structure)
                            enhancedPrompt = buildI2IEditingPrompt({
                                userPrompt: safePrompt,
                                structuralElements: roomAnalysis.architectural_features.join(', '),
                                roomType: safeRoomType,
                                style: safeStyle
                            });
                            console.log('[Vision] Step 2: Generating with I2I using Vision-guided prompt');
                            console.log('[I2I] Prompt preview:', enhancedPrompt.substring(0, 150) + '...');
                            // Step 3: Generate with Image-to-Image (I2I)
                            // ‚úÖ REFACTOR: Passing sourceImageUrl as referenceImage
                            imageBuffer = await generateInteriorImageI2I({
                                prompt: enhancedPrompt,
                                referenceImage: sourceImageUrl,
                                mode: 'inpainting-insert', // Default for renovation
                                aspectRatio: '16:9',
                                numberOfImages: 1,
                                modificationType: modificationType || 'renovation'
                            });
                            console.log('[I2I] ‚úÖ Generation complete using Vision-guided I2I');
                            console.log('[T2I] ‚úÖ Generation complete using Vision-guided T2I');
                        }
                        catch (visionError) {
                            console.error('[Vision] ‚ö†Ô∏è Analysis failed, falling back to standard T2I:', visionError);
                            // FALLBACK: Use standard T2I generation
                            console.log('[Fallback] Switching to standard Text-to-Image generation...');
                            enhancedPrompt = buildInteriorDesignPrompt({
                                userPrompt: safePrompt,
                                roomType: safeRoomType,
                                style: safeStyle,
                            });
                            imageBuffer = await generateInteriorImage({
                                prompt: enhancedPrompt,
                                aspectRatio: '16:9',
                            });
                        }
                    }
                    else {
                        // ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
                        // ‚ú® TEXT-TO-IMAGE CREATION MODE (existing flow - unchanged)
                        // ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
                        console.log('[Hybrid Tool] ‚ú® Using TEXT-TO-IMAGE generation (creation mode)');
                        console.log('[generate_render] Calling Imagen REST API...');
                        // Build enhanced prompt (existing logic)
                        enhancedPrompt = buildInteriorDesignPrompt({
                            userPrompt: safePrompt,
                            roomType: safeRoomType,
                            style: safeStyle,
                        });
                        // Generate image (existing flow)
                        imageBuffer = await generateInteriorImage({
                            prompt: enhancedPrompt,
                            aspectRatio: '16:9',
                        });
                    }
                    // ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
                    // üì§ UPLOAD TO FIREBASE STORAGE (common for both modes)
                    // ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
                    // ‚úÖ BUG FIX #7: Validate image buffer before upload
                    if (!imageBuffer || imageBuffer.length === 0) {
                        throw new Error('Generated image is empty or invalid');
                    }
                    const maxSizeBytes = 10 * 1024 * 1024; // 10MB limit
                    if (imageBuffer.length > maxSizeBytes) {
                        throw new Error(`Generated image is too large: ${(imageBuffer.length / 1024 / 1024).toFixed(2)}MB (max 10MB)`);
                    }
                    console.log(`[generate_render] Image validated: ${(imageBuffer.length / 1024).toFixed(2)} KB`);
                    // Upload to Firebase Storage with session-scoped path
                    const { storage } = await import('./firebase-admin');
                    const bucket = storage().bucket();
                    // ‚úÖ BUG FIX #2: Add unique ID to prevent race conditions
                    const timestamp = Date.now();
                    const uniqueId = crypto.randomUUID().split('-')[0]; // First segment for brevity
                    const fileName = `renders/${sessionId}/${timestamp}-${uniqueId}-${safeRoomType.replace(/\s+/g, '-')}.png`;
                    const file = bucket.file(fileName);
                    await file.save(imageBuffer, {
                        contentType: 'image/png',
                        metadata: {
                            cacheControl: 'public, max-age=31536000',
                        },
                    });
                    // Generate Signed URL (valid for 7 days)
                    // This replaces makePublic() for better security
                    const [signedUrl] = await file.getSignedUrl({
                        action: 'read',
                        expires: Date.now() + 7 * 24 * 60 * 60 * 1000, // 7 days
                    });
                    const imageUrl = signedUrl;
                    console.log('[generate_render] ‚úÖ Image uploaded (secure signed URL):', imageUrl.substring(0, 50) + '...');
                    // Return URL directly - Gemini will receive this and include it in response
                    return {
                        status: 'success',
                        imageUrl,
                        description: `Rendering ${safeStyle} per ${safeRoomType}`,
                        promptUsed: enhancedPrompt
                    };
                }
                catch (error) {
                    console.error('[generate_render] Error:', error);
                    return {
                        status: 'error',
                        error: error instanceof Error ? error.message : 'Image generation failed'
                    };
                }
            },
        }),
        submit_lead_data: tool({
            description: 'Submit collected lead data (contact information and project details) to Firestore',
            parameters: SubmitLeadParameters,
            execute: async (data) => {
                try {
                    console.log('[submit_lead_data] Saving lead to Firestore:', data);
                    const { getFirestore, Timestamp, FieldValue } = await import('firebase-admin/firestore');
                    const { db } = await import('./firebase-admin');
                    const firestore = db();
                    await firestore.collection('leads').add({
                        ...data,
                        createdAt: new Date().toISOString(),
                        source: 'chatbot',
                        status: 'new'
                    });
                    console.log('[submit_lead_data] ‚úÖ Lead saved successfully');
                    return {
                        success: true,
                        message: 'Dati salvati con successo! Ti contatteremo presto.'
                    };
                }
                catch (error) {
                    console.error('[submit_lead_data] Error:', error);
                    return {
                        success: false,
                        message: 'Errore nel salvataggio dei dati.'
                    };
                }
            }
        })
    };
}
